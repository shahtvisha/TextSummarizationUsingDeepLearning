# Text Summarization Using Deep Learning
In the realm of information processing, where effective textual compression mechanisms have become essential, Automated Text Summarization stands out as a pivotal solution. With this exponential growth of digital content across various domains, the ability to distill key insights and essential information from voluminous textual data has become increasingly indispensable. 

There are two primary methods to implement text summarization, extractive summarization and abstractive summarization. Both these techniques use different approaches to automate summarization; Extractive Text Summarization (ETS) extracts important key words and phrases present in the corpus and uses them in the summary, in this process the text remains the same, Abstractive Text Summarization (ATS) is a method that generates new phrases to present the most important pointers and information from the original input. Examples for ETS implementations are graph based algorithms such as TextRank or machine learning models such as classification and clustering, however ATS mainly uses natural language generation which include neural networks models such as LSTMs and Transformers. 

In this repository, I am working on different datasets and approaches for Text Summarization. 

# Contents
CNN/Daily Mail Text Summarization

Pubmed Text Summarization

Finetuning Google's T5

Evaluating Finetuned model and other models 

# Research
Link to research about text summarization: https://docs.google.com/spreadsheets/d/1aMGa38GfarF3Nv4lhF9Z8pKzVjzSW6o_qn3pKibSEGo/edit?usp=sharing
